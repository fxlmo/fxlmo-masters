{"date": "2022-02-02 05:28:42.580000+00:00", "ticker": "AMZN", "mrkt_info": {"open": 2991.47, "close": 3012.25}, "html": "<div class=\"storyContent\" lang=\"en\"><style type=\"text/css\">.storyContent * {border-color:inherit !important;outline-color:inherit !important;}</style><div class=\"storyframe\" id=\"storydiv\"><div class=\"TEXT\" id=\"storybody\" name=\"storybody\"><div id=\"storybodycontent0\"><span class=\"storycontent\"><pre>Click the following link to watch video: <a href=\"https://share.newscasts.refinitiv.com/link?entryId=1_gfcexon3&amp;referenceId=6294667937001_B35&amp;pageId=RefinitivNewscasts\" data-type=\"url video-url\" translate=\"no\">https://share.newscasts.refinitiv.com/link?entryId=1_gfcexon3&amp;referenceId=6294667937001_B35&amp;pageId=RefinitivNewscasts</a></pre>Source: Real Vision<br/><br/>Description: The gaming and animation industries are entering a new era, and Jules Urbach, CEO of OTOY, is at the cutting edge. Growing up a Star Trek fan, Urbach was fascinated by the idea of a Holodeck. This futuristic tech is not yet possible, but Urbach is making studio-tier rendering accessible to independent digital artists and game designers with the RNDR token. Virtually all movies, video games, and TV shows involve massive levels of rendering these days. Urbach\u2019s blockchain approach allows large numbers of decentralized computers to pool their work. The RNDR token is also being used to incentivize NFT rendering, creating a real decentralized community of artists and technologists. Urbach explains it all in an interview with Santiago Velez, co-founder and R&amp;D lead at Block Digital. Recorded on January 25, 2022.<br/>Short Link: <a href=\"https://refini.tv/3oeAnxz\" data-type=\"url\" class=\"tr-link\" translate=\"no\">https://refini.tv/3oeAnxz</a><br/><br/>Video Transcript:<br/><br/>&gt;&gt; Welcome to Real Vision. My name is Santiago Velez, co-founder of Block Digital Corporation. And I'm excited today to bring to you Mr. Jules Urbach, CEO of Otoy. Welcome. &gt;&gt; It's a pleasure to be here. Thank you so much. &gt;&gt; So I'm really excited to have you on the channel today to discuss lot of the things you're working on. I personally think that Render network, which is one of the things we'll talk about today, is probably a very seminal moment in how compute is distributed for services, but we'll get into that. Before we do, I'd love to hear about your past, how you co-founded Otoy, and what the motivation was, and what exactly the company does. &gt;&gt; Sure. Well, I'll start with what the company does and then work backwards from there. Otoy is primarily a software company; we are selling package of software that's based around Octane Render. It was the industry's first production-ready GPU renderer. And it's doing amazingly well today, we have a huge audience of artists that have been using it. I think it helped transform the lives of a lot of artists. But the goal of the company was to democratize rendering. And going back to how I started it, I basically, right out of high school, I was 18. So this is early '90s, so it's been about 30 years of work. I was always fascinated by both real-time graphics, I wanted to make video games. That's actually how I got started; I did a game called Health Hub, but I also wanted to make movies. And I wanted to have those two converge and ultimately also be experienced holographically. Big Star Trek fan, so for me, Star Trek The Next Generation, that first episode with the holodeck, that really did open my eyes to how I imagined experiences occurring in the future and Otoy came out of that, really. It was 20 years ago and a man named Ariel Emanuel, he's the CEO of Endeavor and WMIG, and he also helped me get the company going. And he was a huge influence and is huge influence to this very day on the direction I took Otoy, and also put a lot of doors to everyone in the film business, also in the tech side and really one of my closest advisors. So there is a bit of DNA of the games industry and the movie business. But it's been great to get to the point where we had a very inexpensive monthly service, 20 bucks a month, and with that you get all these great tools and also access to the Render network, which is another layer of what's really a whole separate thing from the quarter of software business, but it's very exciting as well. &gt;&gt; That's great. So for our non-technically minded audience, can you define a little bit exactly what is rendering and why do either movie production or artists, etc why do they need to render things and what's the implication; how does that capability play into this vision of a holodeck? What exactly is it? &gt;&gt; So I think rendering is probably best understood. I think most people that go see movies today are familiar with CGI. That's what makes a movie expensive; go to a Marvel movie you're going to see tons of crazy things that are not filmed, they're computer-generated. So rendering is typically the process of rendering imagery from 3D files, from data, and you end up with an image and hopefully it looks real. I think the beauty of what we built with Octane Render is that it's used to take 40 hours and still does in some cases. For one frame to render on a CPU at normal, this wait was done forever even by Pixar. And graphics cards, the same chips that you put inside of a Playstation or an Xbox that do video games, we program those two to render Pixar quality graphics at about 140th the time and cost. And that is why we did democratized revenue because the larger audience we'd serve is all the individual users that can now turn into their own ILM's. Corridor Crew which makes these amazing bowel videos of Boston Dynamics robots and all this stuff, they did a thing where, we'll just redo the Star Wars Trench Run; Battle of Yavin, over the weekend. And they do it in Octane. And Octane is so fast that it takes the 40 hours per frame that it used to be on a massive render farm, it makes that almost nothing. The problem is that now you have things that are going beyond; the people wanted a render these massive stereo movies with VR and so forth. And so I think rendering is largely anything that makes CG, but you also have graduating video games. And video games themselves, if they are rendered at the same process that a film is, then you have films that are rendered in real-time and that's where the mediver's component comes in a little bit. The rendering is something that people can understand and grasp with CG. And there's tons of CG stuff done in our render in the opening of Westworld and a bunch of two Marvel movies, the openings from Ant-man and Waspm and Captain Marvel, and many. Most of the TV openings that you see are probably done in Octane. Very popular in that [inaudible 00:05:34] especially. &gt;&gt; So Octane, if I understand it correctly, that is a software platform that gives a lot of the technical tools for artists or whoever's in the production flow, the ability to render whatever it is they're interested in. So it's the accumulation of many years of features that continually add on based on the demand and it's just sweet. Similar to how maybe Photoshop or for a graphic designer, this is the software platform for individuals wanting to render and so it has a whole number of in-program physics that help that for lighting, and shading, and things like that. &gt;&gt; Yes, exactly that. So the Octane when it was introduced, it wasn't just faster and on the GPU, it also was spectrally correct, unbiased. What those words mean is that it's like there are no cheats; it just runs the laws of physics for light and you take the certain light that's been metered, an IES slide or something for a spotlight, and you just bounce it off of material that's been measured and you end up with the perfect picture. And you actually can be a cinematographer and just a cinematographer and get really great results set of Octane. And that's also been revelatory for artists. Yes, it runs the simulation of photons bouncing around and you end up with a picture, and it gets exposed; a picture would almost if people remember Polaroids, they would take the pictures instant but it would take a while for the image to show up. That's how rendering with Octane work ; it's progressive rendering. So you get almost instantaneous image created, and the grain goes away with time and that's how the rendering process for our software works. &gt;&gt; That's fascinating because I think underneath that I see several long-term secular currents that are enabling this. The first, obviously, is this change in computing. There is this explosion of GPU processes, either for machine-learning or driverless cars or what have you. But rendering is one of those technologies that seems to really be benefiting from the GPU architecture and so it's very GPU-focused. So I don't think that would have happened had we not had producers like Nvidea or AMD, etc, generating these graphic cards for gamers and then ultimately for industry. The other big trend that I see here that you've touched it to, is this explosion in CGI, in film and movies, television, that seems to be popularized. It's gotten to the point of quality that it's not only acceptable, but it actually adds value to the movie. Would you agree with that? &gt;&gt; I would. I think that if you're looking at it from the Chris Nolan perspective but you can't tell what CGI and what isn't right, then it is additive. I'm not a huge fan of CGI that clearly looks at. I love the old style movies, the Douglas Trumbull era where things were practical and they looked filmed. But really you could do that with rendering. You could do that with CGI. It just requires a bit of thought and art history. There are plenty of artists that are doing that, and I think that's what's so exciting, is that you don't have to create these massive sets with physical objects. With a good renderer, you can actually make that look just as good as if it were filmed. And that's what I love about our software to others. There are other GPU addresses that have come out since we pioneered it and actually they're all on the regular network as well. So it's something like a fraternity of cheap key pioneers, but it is excited to see that. And CGI has become much different the last few years because of the GPU rendering. Nvidia, AMD, and now Apple are all really pushing the envelope and we've been largely Nvidia only for a decade so that thing came out. But recently we've supported Intel AMD and Apple Silicon on the Mac and Apple has been great partner of ours. They collaborate, they've given us huge attention. I was just in the keynote last year for the new Mac Pro, which I'm actually speaking to you on. We're seeing that the CG that was registered for films, Marvel films right on the Cloud and on GPUs, should that be done, believe it or not, on an iPad with an M1, which is crazy and it does work in real time. It's wild. There's no difference between what a phone can render and what you're seeing in him off a movie. It's just a question of time and memory. Then the Apple M1 is not that slow. It's about as good as had mid-range Nvidia GPU, desktop PQ five years ago. &gt;&gt; Wow, that's mind-blowing. &gt;&gt; It is. &gt;&gt; I think with respect to your vision of it being a democratizing power for creators, it really is changing the balance. Before you may have needed a huge pre-production team for the workflow to address every single frame one by one, and maybe a Cloud or a farm of servers. Now, a YouTube content creator could theoretically do it and with very little relative compute. I think that's revolutionary to be honest. I believe that could really change the dynamic about how maybe stories are told and how content is created and distributed. So I could definitely see how it could become a democratizing force that everybody would have access to it. Because it seems to me there's two big pieces. There's the software and then there's the hardware. And you really need both to really empower the end-user. Right now who is old toys larger customers? Is it large studios and workflows, or is it more of a large collection of individual artists and creators? &gt;&gt; Well, it's really, I guess both in the sense that we have most of the need for studios and we keep the licenses come in for this company that's hundreds of seed, but that's really not the customer base. The customer base is I would say, Adobe says, it's individual artists. A lot of 3D artists using Octane come from Adobe Illustrator or Photoshop. They're graphic designers now they want to learn motion graphics so they want to get into 3D design. And we're super simple tool to use. So that's the majority of our growth, especially the last four years. And it's exemplified in some ways by somebody like Beeple who was doing 2D Photoshop things efforts every day for the first few years, learned Octane, and used Octane to do his CG renders. Use CG every day for 8 years, something like that. Obviously he's successive atypical, but he's the kind of person that takes Octane and maybe does it for their own portfolio or hobby work, but also people who's doing Super Bowl commercials and things like that before. Again a few explosion. And so a lot of people buy Octane or use Octane to do motion graphics work for clients, adds, things like that. Although six months ago, less than that, I was sitting next to a young man, 17-years-old, just learned Octane a year ago and sold a $1 million NFT using it. So there's a whole new market for art that I think it's fantastic. I think that was always my hope, is that I believe would be democratized, the creation of RP democratized the way people can make money. And that I think is where NFT is certainly an excuse that are created with these tools. It's fantastic. $800 million worth of art was created in art last year. So that's incredible. I would say that's the audience, not the end of artists necessarily, but just individual artists. That's the goal. Get them everything they need. And of course, yes, if you run an iPhone 11 or later in the tools on there, that's great. We're getting to that point. We're certainly seeing the fact that a phone and an iPad are starting to get to the same level of a GPU that Octane users, professional ones five years ago had on their desktops. So that's that. But also, again, a handheld device or an iPad is super-interesting. But if you had glasses that had the colon of an M1 or better and all of that rendering was done in your eyeballs, that would be really cool. So I'm looking forward to things like that. And even if we have a very fast single GPU and learn device, it doesn't mean that you want to sit there and wait for 1,000 frames or something to get rendered if you're doing a 20-minute video. So that's where the Cloud comes in and rendering comes in. They're still the need for that once the design work is done on your local machine. And that's why rendering exists. And maybe that's a segue way into talking about that part of our ecosystem. &gt;&gt; Yeah, perfect. One common thread here that I think that our audience will understand is this secular trend in the transition from Web2 to Web3, this metaverse space. This idea of a shared environment. I think it's important for people to differentiate, maybe a Web2 version of metaverse. Something like Meta might create Facebook prior to Facebook, where the entire environment is created and controlled by a single counterparty, versus a metaverse that is more of a level playing field where you have everyone with the capabilities and opportunity to create and share or express their content, their version of their universe. And it's more interoperable where people can share it, interact with each other. And it seems to be more of an equitable Internet, if you will. And I think big pieces of that come from products like yours that democratized and empower the individual. So on that note, can you tell us a little bit about what the render network is and what specific problem that attempts to solve? &gt;&gt; Absolutely. Well, since we spend a good amount of time talking about what Octane does and how cheap [inaudible 00:15:49] render is a continuation of that conversation. My good friend goes back to 2004. It's almost predates my founding of votes for it. Because I always imagined that especially if you're rendering for the holiday or you're rendering a holographic content, which is insanely, it's like a 1000 times per frame with [inaudible 00:16:10]. You solve one problem, but only open the door to another. But frankly, even sort of holographic as intimidating, if you're doing a 10K or a 14K spherical panorama, which is huge, and you're doing that at 120 second for a concert. Those are the kinds of renders that people still need the Cloud for. And as it turned out, I wasn't sure if there was ever going to be a GPU Cloud. [inaudible 00:16:32] was one of the first companies to pioneer Cloud rendering with Amazon as a partner. We helped them once [inaudible 00:16:39] since 2013. I went on stage [inaudible 00:16:41] talked about obtaining the Cloud. And prior to that, though I wasn't sure if that would ever happen. GPU use a datacenter were not unknown thing back in 2004. So my idea was to do it set at home and have everyone's computers just running ray tracing operations for future high-end holographic render jobs. And it paid them some fraction of a penny per ray. So what didn't happen here is that we did end up thinking, well, Amazon solved the problem. It's like they're going to have GPUs. Eric Phenytoin never advise report because he's like, I wanted to join this thing but I will make sure Google has a GPUs. GCP was going to go away and resolve as well, and they have tens of thousands of GPUs. But that's not enough. As we've figured out, somewhere in the middle of our launching the service which we launched called Orc on Amazon, where you could send a job, the dollar would unlock a certain amount of rays per hour. That was actually mapped to the Amazon GPU hour price, and to our oxygen bench score. We would have one or two customers who would take all the GPUs in Amazon. And that means you couldn't have two customers a night. And there was one customer in particular, that was like, it's six months of all of the AWS GPUs and it's August and the things due in January and they just gave up. The idea with render was we're facing these issues for years and I couldn't really make a functioning business out of Cloud GPU rendering. And I had done all the work really to bring the customer to the GPUs that were on the public Cloud. We made it so you can export from any 3D tool using orc it would do it all for you. So it was simple to use, but the capacity wasn't there. And because our capacity wasn't there all of the benefits we normally get with Cloud computing the fact that Amazon has funded since pricing instead of a dollar per hour, it's $0.11 if there's capacity. You couldn't get the capacity for dollar per hour. The on-demand price [inaudible 00:18:32] power wasn't there. And so renders solved through those problems at once. I was like, well, there's a lot of people mining a theory and this is 2017. So why don't we just send the jobs. And you can't tell the difference in jobs that's running Amazon's CPUs and the ones that are run on a decentralized GPU on the network. What if we just switched it and say, send to jobs to the [inaudible 00:18:56] and given reputation score and pay them. Off the bench tokens were a tokenized ERC-20 that would represent the occupied bench power. And we had a certain metric already what that was worth because Amazon's costs, believe it or not, for 2013 to 2022 has been almost 10 years. It still costs the same as it did in 2013 in terms of octane bunch of per dollar. What we did is like, well, you have multiple tiers now where it's like the equivalent of spot pricing is one-eighth in costs. Do you want to do to use that and see if it's as faster and better? And of course, it is. In fact we are such capacity on the render network within one week we had 1200 nodes sign-up, 10 GPUs each on average. And those are high-end GPUs, whereas the ones on Amazon were low end. So we had more power than all the public Cloud combined in a week. This is something like a million GPUs versus if you added all that are just waiting to join the network as we add on more artists who work with. That's something that we're going to ramp up, but we're at the point where people are running render, it's life changing. You could send every one of your friends, if it takes a minute to render to a 100 different GPUs. And no matter how long your render is, you can come back in a minute because if the work is parallelized across that many nodes, it is remarkable. I've heard just recently, somebody who was working in a major motion picture about to come out, the budget didn't allow them to find the GPUs, read your on-premise and the [inaudible 00:20:21] was a no-go. So they actually read, heard the movie on render on the de-centralized node, some random person's computer on the Internet was rendering a major film you're about to see. And that stopped the first time those kinds of things have happened, like the Apple keynote that we did and part of that was done on render as well. It's wild the amount of things that are happening. And so my only thought was, well, a Marvel movies probably going to need to still be done in Amazon, which is why we have that there for security reasons. But actually, turns out maybe not so much. Maybe not more fully, but films themselves having end-to-end encryption. There's always security issues with sending your things anywhere outside of on-premise. So it's amazing. The render network solves a problem for filmmakers. And also, by the way, Pak who renders $91 million selling his LFTs at the gaze eyes people, the artists now uses render to vary for his art. So it helps everyone. And I think that we're only going to make it more useful, more expensive. And more importantly, if you're making NFTs, you don't have to make an NFT image anymore. The rendering job itself is all a chain. It's prove for vendor. So you have this hyper verified output asset, but it's actually the job itself either triggering it. These are the two trip metaphors in NFTs and there's nothing quite like it. So I'm excited for that part of the business to really explode. And I think that the NFTs, the [inaudible 00:21:48], maybe these sort of nascent things are aware renders, true strength, you're going to lie for content creators. &gt;&gt; Wow, lot to unpack there. I think you blew my mind there are at least three or four times. So I wanted to dissect a lot of that because there's some golden nuggets there. So first of all, if I understand it correctly, when it was pure ionic Cloud web two let's call it. What we saw is that capacity was saturated almost instantly. And therefore, it was exclusionary by design, but it's capacity. So it could not accommodate, essentially in a democratized way, everyone who may want to use those resources. So that was kind of like problem one that really caught my ear here. And that's very surprising because these are massive data centers whose job it is to do load balancing and all that good stuff. So that's very interesting to hear. Then it seems like on top of that, you also created a platform for taking a job, breaking it up into millions of little pieces, sending it out onto the Internet. Kind of like you mentioned, SETI, which was a search for extraterrestrial intelligence program that will run on your screensaver would use your scram capacity on your computer when you weren't around. I think that's clever. This idea of distributed computing. We take a very high compute job, break it up into lots of pieces, send it over the Internet, have those pieces processed, and then reaggregate it back to the original client. I think there's something very special there. Then finally what I hear is that this has been occurring almost in parallel with this other trend in the way that content is created and monetized. And you mentioned NFTs. And you talked about specific artists. And if TRS like people that created very special and unique things using the octane and render technologies. So all of that, just alone is a mind-blowing exercise. So I appreciate you sharing that with us. Going forward, I guess I have lots of questions now. The individual providers of the compute must therefore be incentivized to provide their compute for some reason, what do they get in it? You mentioned a render token or asset, and that in some ways correlated to the capacity and pricing ratio that you're used to seeing with Amazon. Can you talk just a little bit more about that? &gt;&gt; Yeah. It is straightforward in the sense that one rendered token at which a total half a billion were remitted and there's a hundred and something million in circulation. The token themselves at minimum they do $0.25 of work than you'd get an Amazon never less. And sometimes a token at one point was worth three cents in the open market. So we can still get 25 cents of compute power from that, it can also do more, but never less. It is something where at the very least we're paying you a unit of value that now we're on almost every exchange except the point-base, I'm sure that will come at some point. You can get paid and you can turn that into money or you can hold it and you can render it yourself with it. And there are other layers things you can do with it in a token that you can't do with a piece of money, so there are interesting bits there. But it's that simple, we're basically play shifting the jobs from Amazon to these nodes, instead of mining Ethereum, you're rendering for render tokens. Then render token gives you at least 25 cents if you're doing the same work than Amazon is going to be doing. What we found was that a lot of node operators, they want to make money. You can't really make money mining cryptocurrency as much anymore. When Ethereum moves to proof of state, you're going to lose a lot of GP power, that was for hashing. So here we come in where I think even at its best when cryptocurrency mining on GPUs was profitable, we're 47 times more of a render job. If you can do that on your GPU, it pays out like 47 times in mining job to do. So it is one of those things where if you're cheap to run the network, it's like maybe if we get 30% usage where you get a drop 30% of the time, that's pretty good. I mean, if you go higher, but that's where it is roughly for a lot of users. But even so, you can always run another crypto mining currency job while you're not doing your render job that's been set up. But when you do get a render job that kicks in, it's a big payout. So we've had no trouble signing up node operators for that. In fact, what we wanted to do is you want to make sure that they're reputable and reliable and so is like an Uber score. So it's like, you get five-stars, you get called on for more rides. It's the same thing. It is decentralized, but it also isn't completely reputationalist either. There is the fact that your wallet that you're now achieving these things from does have score reliability factor. You could assign yourself to certain tier and that matters, that makes a big difference. But the way that it works, I mean, the smart contract for how render works is that we watermark the images. Basically, when somebody does a render and the artist's gets back. What they should want as their image, there's a watermark on it and told they say, this is what I wanted and the watermark gets removed, the money is held in escrow. The second the artist says, this guy rendered what I wanted or this person rendered what I wanted, then the watermark goes away. The artist get's a final file and the node operator who did the work get's reward and it works perfectly. It's been working really well for awhile. If anything, the hardest problems we've run into are the fact that one is just obviously the [inaudible 00:27:51] crazy. So we went to [inaudible 00:27:52] and that's been better, but it's not a perfect system either. We're working very closely with [inaudible 00:28:01] and the team there to see if we can get an even better result in the future. I mean, obviously we are multi chain, so we're not tied to one particular blockchain, but I think that we're definitely looking to get beyond some of the security issues that are on Layer 2 solutions. I mean, it's not a perfect system even if it's fast through trading scheme for security. But it's amazing that this is all possible on Web3, and we're just at the very first layer of value where the token itself is also something you can use for doing royalties, on NFT cells that you're doing on [inaudible 00:28:34]. So it's not just that you're paying for Amazon power. There's more to the token than that, and there's much more than we wanted to do with it beyond just the compute side. &gt;&gt; Well, interesting. So I guess first question. So it seems like you manage the counterparty risk between the artist and the compute provider and you've given them a pretty [inaudible 00:28:53] a watermark way of addressing that for both parties. So everybody is satisfied with the product in the end, our payment is held in escrow and then delivered upon satisfactory completion of the job. So I think that's very clever. And then you mentioned that you have a reputation system and I'm sure a performance rating, because not all of the GPUs out in a decentralized network are the same. So they must have some kind of rating structure for their ability to perform a unit of render. So all those things being considered now, you have this operating network, you have a wage for people to transfer work for value, and then you have a way for the free market to price that digital asset , but whatever it is. So does the minor that essentially accept the volatility risk of the token or does the artist? Because I imagine the artists must source, render token. In other word to get a job done or do they pay in a fiat currency? &gt;&gt; That's all the great questions. Let me start with the benchmark. So we have something called OctaneBench, which has been around forever. Nvidia, Apple and many others use it and frankly most GPU render farms. Whether they even have a license [inaudible 00:30:07] or not, the OctaneBench score of your GPU is pretty big deal. So what happens is when you sign up to the render network and I think benchmarks works when, if you have two 1080 *** it's double the [inaudible 00:30:18] bench score and they mix it together. You can add it all up and the more GPUs you can squeeze into one box or even network together, the larger your OctaneBench score will go. It's a perfect unit of render work. So you run OctaneBench before you even join the network and runs every time by the way, anytime you change your hardware state. I think bench score is a very good indicator of how long it'll take a certain amount of oxygen bench to get done. So you're basically paying how many trucks in bench times, how much time is the work involved. So there's a very clean metric for that. And then as far as the artists go, yes you can go and you can get tokens from the open market or you can earn tokens for render jobs and you could spend those on jobs. 97% I'd say if the artists that are currently used in the render network, believe it or not, they don't know crypto that well, they don't have a cryptocurrency wallet. We're talking about a lot of people, not everybody is crypto centric, not everybody's doing NFTs and is with familiar with that space. So for them, it's like they just want to spend, like they've been [inaudible 00:31:23] the dollar rendered credit that we'd sell for Amazon was certain amount of OctaneBench. That's still the case today except the difference is you're giving us a dollar. We made a very public announcement, I think it was sometime in 2020, it's been a [inaudible 00:31:37] here. We're going to buy from the open market three million rendered tokens, something like that and we have a reserved. So when the artist need to spend a dollar, we take the token out regardless of the price or the token. I think three cents when we bought it is probably a 100 times that now and we basically then provide the node operator with a token. So the note operators are always getting paid in tokens. The artists can choose whether they wanted to spend tokens or a dollar. But John Knoll, the head of ILM, who's our briefers customer did not want it even deal with crypto. He's like, can I just pay you a dollars and can I get this drop to the hidden a planetarium done in the next hour, which we did and it was amazing. And that's your first dollar into storage. You make your first sale like that was the equivalent that for render it was, John is god, amongst the visual effects and CGI and everything. So it was amazing and it worked great for him and many others since then. But there's a lot of artists and even studios are just not that crypto savvy. So it's always easy to pay with your crypto with a credit card and maybe that'll happen. We are in that world where we have to provide an easy on-ramp for artists. That's something that won't necessarily be the case in the future. As I said, it's crypto becomes much more part of everyday life for payments, but right now, there is a separation, but we do. It's already your tokens on the other side. So that's how the system works currently. &gt;&gt; That's super fascinating because I can see the utility of the token in the network as a measure of compute. And I can see how the network and the supply and demand of that would just find price discovery for that. I think that's beautiful. What I think is interesting about creators, human beings in general is whenever their spare capacity, they tend to figure out a way on how to use it. So it doesn't seem like there's a limit anytime soon. To your point about if we extrapolate to a holiday scenario where everything is completely virtualized around us, the amount of compute that would take, it's mind-boggling. So I don't see an end anytime soon. It take a very simple example. People at home watching used to be 720P or 1080P TVs, a 4K, UHD. And you get into frames per second and all your bit rates. And before you know it, you eat up all the capacity. And now we're talking VR and AR and all of these things. So I can see the fact that data centers probably would not have been able to keep up with that trend anyway. And it was just a matter of time that decentralization was really the only way that you could deliver on this ongoing appetite for better, more quality and capability. So I think you've done a great job then creating an architecture for that. Can you tell us a little bit about in the specific case of NFTs? What exactly because I've read a little bit about renderer does some special things as it relates to NFT, non-fungible tokens and how they are? Can tell us a little bit about that and why an artist might use render for entities. &gt;&gt; So that's a use case. First of all, we find that all the time that all these NFTs are rendered or unrendered. Just remember we have no insight. I'm somebody has to tell us this is where they come to us for support which popped out as you like, can you help me with this render drop like or this artist being done the rent. What's interesting is that a lot of NFTs are typically it's an image at the end of the day or video. And you're getting some content. This essentially as a movie or a static image, but there's something special about it. What's interesting is the rendered network allows you to create these beautiful images. But if you want to get a 5,000 additions, each with a slightly different variation, it's not a Photoshop layer. That's what people are using renderer for. They're like, I'm going to render a 5,000 of these metro robots, each with a different shader material and they actually program that into the render a job. So you end up with something that allows you to spit out 5,000 of the same images or 10,000 of these things or 10,000 these videos all different. And I guess that is in some ways that exemplifies exactly where I think render is useful as an NFT creation tool because it can't give you this high fidelity. Almost machine like reproduction with slightly different variations. But if you take it one step back, if the output is in the image and make sure you can render it but the actual NFT is the job. Remember everything's on chain, everything is diffused. It's something where validator nodes, the entire value of render is from proof for vendors. So the very fact that you could just call upon a rendered to generate an image means you don't have to pre-render fact thousand things. It could just be rendered when you have it and that's something that actually means you own the render. Because there is only there's unique fingerprint for the DNA of the files, the assets, who owns what goes into it. More importantly, if people could attribute models for textures, those can also be in there. I think that the future of NFTs, it's not just running a render to get the output. It's the actual rendering itself that people can start to appreciate especially in metaverse where rendering is constantly happening and it's not a metaverse if it's a movie. If you're constantly rendering these assets and that's where again, the real-time part happens. It's fascinating and we built a match and say that's one important component we've added towards an open metaverse is we're absolutely backing open status. When everything that runs on render is based on open source, open standard called ITMS, submitted a cable labs, their video, codecs and other standardization things. Also, I'm on the Chelsea F Working Group. This week and every week our topic metaverse components with GLTF, and also working with this one the metaverse seam on helping because their marketplace strategies is very nascent. It's really open-minded. And I'm like each of the things that we want to see in NFTs. They're all these interesting partnerships for helping create what I would consider open standards for how NFTs metaverse 3D assets can all inter-operate. And more importantly on render, we've also added two competing renders. It's not just octane, their friends. It's a small space, but they do compete in a sense for the market which is redshift from axon amazing team to render and Arnold, which is another fantastic render all on the GPU as well. And that's important like having a decentralized render network means having not just Oh, toy or octane software, but all software on their open standards. And that means that when you're creating an NFT, it's not dependent just on us, the system continuous. That's the beauty of render and that's a web 3 piece that a lot of web 3 companies just don't get. &gt;&gt; Wow. That's amazing. That's you. Let me see if I can unpack that because a lot there as usual. So the data for itself that the rendering process represents is on chain. And when you say on chain, you don't mean the Ethereum blockchain. You mean the render network itself. It's available as a data primitive that anyone else theoretically could use. Is that correct? But whereas physical. Go on. &gt;&gt; So [inaudible 00:38:59] activity, so caches for every single file, we don't even filenames diffused into that. You could all be packed in IPFS or ARB because that's all they are is a hash to data. So there is an XML file that tells you how to render right now. The one thing we do is if you don't own that, you don't want somebody else to render your render. You can't. But it was people that was like, what if I give somebody the ability to render my job and I just sign it to them and that's an NFT. And what happens every time a job is done, the receipt, the hashes of everything going into the job and the hashes going out are therefore hash. And you actually know how much was paid for the job because that's on the blockchain. So the receipt of these things are there. And by the way, the entire render network itself is on a ledger that predate in Ethereum. Every single chopstick is attached for every render is in an index. First upload, all of that was on S3, and then we basically have that now in a hashed database so we can put an arrow. So you can look at that and that's the thing. You don't need even the blockchain itself. Now that you have things like air, we've had TFS, you can store tons of data there, reference that on multiple chains. And that actually is also a very efficient way of dealing with future entities and smart contracts in the medication. &gt;&gt; Wow, so what we're really talking about, there are property primitives. We're talking about property primitives and having provenance back to its creation, its instantiation. Yeah, I'm sure you can basically authentic key down to its creative level how something came into being, who owns it, what the energy and effort went into creating it, and then express that in a public way than anybody can verify that, is that correct? &gt;&gt; That's correct. &gt;&gt; Wow, that's a big deal. &gt;&gt; Hyper-provenance, so omega provenance. It's like even avenues in bits. As your opinion, you don't know exactly whether the original units the thing is. There's something about this where every people, Mike uses a lot of stuff from the TurboSquid and it's like all of those assets or hash every attempt to use as a trapeze good asset in any render, we know what the 3D model is. He's got a fingerprint just like edit it's wild. You have this in there every job on render and he couldn't back now to 2015 because it predates render beyond on the blockchain. We know where those assets come from. Every single thing can be proved. And so there's at least 70 years of people's stuff where we can do that. With me, it's awesome. And that's where archiving, in particular, wanting to use the system to archive important IT. We're doing that with Gene Roddenberry's work, his son is my best friend. And so we've been doing this project for years. It was very publicly announced and August Albatross, who you see the paintings, he's also one of my closest friends, 25 years and working all of his work. And we're actually building 3D assets for every one of his paintings in addition to having the paintings in the archives. So key can art direct that. And that also goes on renders. And you can use those things, could be used to generate a new shorter become the standard industry I wonder. But there's like to see that, there are all these things where it's amazing. So I'm building almost like the seed back to the repository, I think for future medical history telling content with specific things that we're involved with but those are also meant to be templates for others to follow. And I loved that. That's the most fun part of the business so far for me. &gt;&gt; Wow, when I first started this should give you, I thought that the kind of revolutionary component was going to be this idea of taking something on the compute stack and using the technology of decentralization. Basically, they get more efficient and increase capacity. But what I'm actually finding out here is that the revolutionary part here is the property primitive and the ability to create things on top of that primitive royalty structure, or IP, or licensing, or any number of things that the creator could imagine and monetize using the decentralized network. Thank you for that. I appreciate you sharing that. So I don't want to take too much of your time. I do want to get an insight on where you think render token, render network, and Ottawa are going, let's say in the next six months, five years. What's your long-term vision or passion? Is it the holiday? &gt;&gt; Yes. Let me switch to the holiday part first because I think there's some specific stuff that I can share. So in September, one of our partners, MetaLab, they make holographic display panels. I wasn't very early backer of that company drive carefully is a genius who runs that organization used to be a light truck. They make panels from their 20 inches by 20 inches. Seen interested in news article on it or report divide the presidency. That is our target. They take all the Roddenberry archive work that we've been working on, including destruction enterprises, your museum quality assets that are big curated by Mike Fukuda, people who worked on the movies and the show. We're going to render them live on these holographic display panels. So these display panels are expensive. People like Watson for his physical art. But they're going into museums and theme parks in the light. But you can tile them together. So it's like the Samsung wall. You can actually then put them in corners increases. You can't create the holiday. And I feel like we're 300 years early, but yes, that's the holiday. Light elapses way paddles. The only problem is it requires 1687,600 GPUs to power currently 120 inch panel, go down to one GPU in the back of the panel in the next few years. But that's going to be an alternative to experiencing the megadiverse with that pair of glasses. And I think it's going to be preferable because nobody likes putting on glasses. Nobody wanted to put on glasses even lightweight went through 3D TV. We'll be experimented with that and then render network we've got live streaming. So we're going to be able to give you not just jobs that are rendered in a high-latency thing offline, but actually, you have enough CPU power. And I wanted to see, must say this starts by enterprise. I'm going to go in there. I went to see it live. And we're going to be having another tier coming up that'll allow you to do live stream nodes and you'll have them live in a fuse that are actually metaverses. All we need is a web browser. If you go to toy.com, there's a couple of demos of this type. You've had it forever since 2014 where you can actually run at, I've seen in a browser and there's Unreal Engine NFT that's done with document friend real, that's a web stream. And so putting those into meta plate is actually one of my next volts because the meta plate and if the ecosystem allows for these streaming and its use. On the [inaudible 00:45:31], we just have absolute awesome tech coming. We are going to be more and more towards real-time. That's going to be necessarily because holographic displays require 1,000 times more compute power. So anything that accelerates things further towards real-time at to care for cake. Absolutely, necessary when you're dealing with 10 gigapixels per square meter is what a holographic display request. That's this year. &gt;&gt; That's unbelievable. That's amazing. We need to have you back here on real vision to continually update us, the audience on your progress. It's going to be mine blazingly fast. I can see that already. I'm very excited to see how things go. Was that something you'd be interested in doing? &gt;&gt; I had left him. This is great. &gt;&gt; Well, I'd love to pick your brain for about three hours, but very respectful of your time. So I want to thank you on behalf of real vision and the audience, and we'll see you soon. Thank you. &gt;&gt; Thank you so much. It was a pleasure. &gt;&gt; Hey, there. Since you got to the end, I'm guessing you liked the video. And that's probably because we don't just turn on a camera and film. We work really hard on getting the narrative flow just right. And that's why many finance companies are actually now hiring real vision to make videos for them. One of our recent client videos just hit 100,000 organic views on YouTube, and there were no kittens inside. So if you want to find out how real vision can make a video for your company, just email us at customvideo@realvision.com.<br/></span></div></div></div></div>"}