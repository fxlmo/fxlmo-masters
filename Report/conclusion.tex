\chapter{Conclusion}
\label{chap:conclusion}

\section{Contributions and Achievements}
This project presents an implementation for the algorithm described by \textcite{sestm} that is able to take labelled financial headlines and construct a model of words that can then be used to predict stock movement the day after a headline release.

To complete the model, I have written more than 3000 lines of code. The three main components of this project are the pre-processing, the model training (SESTM implementation) and the evaluation (generation and evaluation of portfolios formed). The choices I made regarding the pre-processing of the headlines are presented in \ref{sec:pre-processing}. The full implementation of the SESTM algorithm is detailed in \ref{sec:training-model}, while the evaluative methods of the constructed portfolios are discussed in \ref{sec:oos-testing}.

The level of the model's predictive quality has been evaluated according to volatility, as well as overall returns in \ref{sec:daily-returns-analysis}, using simulated portfolios on out of sample headlines. The theoretical returns are calculated using real market data from \textit{yfinance} \parencite{yfinance}, and as such reflect the real world capabilities of the model.

A comparison between the potential profits of the portfolio generated by this model and other available techniques is available in section \ref{sec:comparison}. The comparison highlights the success of the algorithm in predicting positive sentiment, while also drawing attention to the shortcomings in gleaning negative sentiment.

\section{Current Project Status}
In the current state, a fully functional SESTM implementation is in place, with a number of evaluative steps taken as a measure of success. Of the original outlined aims, I have completed the majority of them. The first aim, to implement and optimise SESTM has been achieved fully as evidenced in Section \ref{sec:implementation}. I spent considerable time optimising and tuning my implementation, as the runtime can become very long.

The second aim was to successfully train a model using the dataset of financial headlines, using stock returns as a teaching signal. This has also been fully completed, and can be seen in Section \ref{sec:training-model}. The various models trained over the course of the project can be found at the following url: \url{https://github.com/fxlmo/fxlmo-masters/tree/main/kaggle/data/models}.

The third aim was to evaluate the success of the model by evaluating portfolios. This has been achieved somewhat, although the out of sample data contained data that was irregular, meaning it was less reliable than originally thought. The results can be seen in Section \ref{sec:daily-returns-analysis}. 

The fourth and final aim was to compare the performance of SESTM against other sentiment analysis techniques. This has been completed, and shown in \ref{sec:comparison}. The performance is shown to be comparable to other methods, and even slightly outperforms by some metrics.

\section{Future Work}
While the project can be considered complete, it would benefit from further training with a larger dataset. As headlines are very short pieces of text, the required dataset for good accuracy would be very large, and so training and testing this model with another, larger dataset would be beneficial to create a more reliable model. Furthermore, doing analyis using such a database would provide to be more insightful, as it offers more data.

A potential use for the algorithm could also be to be used in predicting market crashes. In the Kaggle dataset used, specifically the out of sample set, the COVID-19 outbreak occurred causing the stock market to plummet. I did not compare the sentiment scores of articles during and before the crash. However, there could be information to be gleaned from performing analysis on these two values. The trends in predicted sentiment overall could be used as an indicator for market volatility, and could serve as an interesting foundation for future work.

\section{Conclusion}
Ultimately, SESTM is able to effectively estimate the positive sentiment of a financial headline, and use this to correctly predict the positive movement of a stock on the following day, particularly when trained with bigrams. Unfortunately, the performance is not the same when considering the negative sentiment of a headline, and predicting downward movement in a stock. This is potentially due to the small size of the dataset, and so would benefit from further investigation with more data points.

It is shown that the algorithm performs comparatively with other methods, and generates private information not shared by such methods. It is, however, more flexible than other methods, as it is easily able to be reconfigured when new data appears, and as a result is able to remain relevant, as the model can simply be retrained.


% \noindent
% The concluding chapter of a dissertation is often underutilised because it 
% is too often left too close to the deadline: it is important to allocate
% enough attention to it.  Ideally, the chapter will consist of three parts:

% \begin{enumerate}
% \item (Re)summarise the main contributions and achievements, in essence
%       summing up the content.
% \item Clearly state the current project status (e.g., ``X is working, Y 
%       is not'') and evaluate what has been achieved with respect to the 
%       initial aims and objectives (e.g., ``I completed aim X outlined 
%       previously, the evidence for this is within Chapter Y'').  There 
%       is no problem including aims which were not completed, but it is 
%       important to evaluate and/or justify why this is the case.
% \item Outline any open problems or future plans.  Rather than treat this
%       only as an exercise in what you {\em could} have done given more 
%       time, try to focus on any unexplored options or interesting outcomes
%       (e.g., ``my experiment for X gave counter-intuitive results, this 
%       could be because Y and would form an interesting area for further 
%       study'' or ``users found feature Z of my software difficult to use,
%       which is obvious in hindsight but not during at design stage; to 
%       resolve this, I could clearly apply the technique of Smith [7]'').
% \end{enumerate}

% =============================================================================

% Finally, after the main matter, the back matter is specified.  This is
% typically populated with just the bibliography.  LaTeX deals with these
% in one of two ways, namely
%
% - inline, which roughly means the author specifies entries using the 
%   \bibitem macro and typesets them manually, or
% - using BiBTeX, which means entries are contained in a separate file
%   (which is essentially a databased) then inported; this is the 
%   approach used below, with the databased being dissertation.bib.
%
% Either way, the each entry has a key (or identifier) which can be used
% in the main matter to parencite it, e.g., \parencite{X}, \parencite[Chapter 2}{Y}.
%
% We would recommend using BiBTeX, since it guarantees a consistent referencing style 
% and since many sites (such as dblp) provide references in BiBTeX format. 
% However, note that by default, BiBTeX will ignore capital letters in article titles 
% to ensure consistency of style. This can lead to e.g. "NP-completeness" becoming
% "np-completeness". To avoid this, make sure any capital letters you want to preserve
% are enclosed in braces in the .bib, e.g. "{NP}-completeness".